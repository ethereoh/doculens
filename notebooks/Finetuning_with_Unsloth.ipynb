{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adPFkr24jVBr"
      },
      "source": [
        "## 1. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2eSvM9zX_2d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc6df15-4f02-4f4f-f5d0-75a8c907a22e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2024.10.6-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting unsloth-zoo (from unsloth)\n",
            "  Downloading unsloth_zoo-2024.10.4-py3-none-any.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (2.5.0+cu121)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting bitsandbytes (from unsloth)\n",
            "  Downloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth) (24.1)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.8.14-py3-none-any.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: transformers<4.45.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.44.2)\n",
            "Collecting datasets>=2.16.0 (from unsloth)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth) (1.26.4)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.34.2)\n",
            "Collecting trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.11.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting peft!=0.11.0,>=0.7.1 (from unsloth)\n",
            "  Downloading peft-0.13.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth) (0.24.7)\n",
            "Collecting hf-transfer (from unsloth)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.34.1->unsloth) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.16.0->unsloth)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.16.0->unsloth)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth) (3.10.10)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=2.4.0->unsloth) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0->unsloth) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<4.45.0->unsloth) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth) (13.9.2)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.18.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth) (0.2.0)\n",
            "Downloading unsloth-2024.10.6-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.6/164.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.13.2-py3-none-any.whl (320 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.11.1-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.4/318.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.14-py3-none-any.whl (109 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.8/109.8 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post2-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.44.1-py3-none-manylinux_2_24_x86_64.whl (122.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.4/122.4 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2024.10.4-py3-none-any.whl (39 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, triton, shtab, hf-transfer, dill, multiprocess, xformers, tyro, bitsandbytes, peft, datasets, trl, unsloth-zoo, unsloth\n",
            "Successfully installed bitsandbytes-0.44.1 datasets-3.0.2 dill-0.3.8 hf-transfer-0.1.8 multiprocess-0.70.16 peft-0.13.2 shtab-1.7.1 triton-3.1.0 trl-0.11.1 tyro-0.8.14 unsloth-2024.10.6 unsloth-zoo-2024.10.4 xformers-0.0.28.post2 xxhash-3.5.0\n",
            "Found existing installation: unsloth 2024.10.6\n",
            "Uninstalling unsloth-2024.10.6:\n",
            "  Successfully uninstalled unsloth-2024.10.6\n",
            "Collecting unsloth@ git+https://github.com/unslothai/unsloth.git (from unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git)\n",
            "  Cloning https://github.com/unslothai/unsloth.git to /tmp/pip-install-04930t0x/unsloth_2947c84adc3d457d9a8c075353ced05b\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth.git /tmp/pip-install-04930t0x/unsloth_2947c84adc3d457d9a8c075353ced05b\n",
            "  Resolved https://github.com/unslothai/unsloth.git to commit 4f1c474d4a4d75529677db96a0031fd8d57ab696\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: unsloth-zoo in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.10.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.8.14)\n",
            "Requirement already satisfied: transformers>=4.44.2 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.44.2)\n",
            "Requirement already satisfied: datasets>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.66.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.44.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.26.4)\n",
            "Requirement already satisfied: protobuf<4.0.0 in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.24.7)\n",
            "Requirement already satisfied: hf-transfer in /usr/local/lib/python3.10/dist-packages (from unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.12.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.44.2->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.19.1)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (13.9.2)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.5.0+cu121)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.0)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.34.2)\n",
            "Requirement already satisfied: trl!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.11.1,>=0.7.9 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.11.1)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.13.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (2024.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.16.0->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (0.2.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->unsloth-zoo->unsloth@ git+https://github.com/unslothai/unsloth.git->unsloth[colab-new]@ git+https://github.com/unslothai/unsloth.git) (3.0.2)\n",
            "Building wheels for collected packages: unsloth\n",
            "  Building wheel for unsloth (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for unsloth: filename=unsloth-2024.10.6-py3-none-any.whl size=163724 sha256=0b838048f8e37690d89efa836be15b710b80e7e04102f982ceec22900ebd67b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-q81vzd19/wheels/ed/d4/e9/76fb290ee3df0a5fc21ce5c2c788e29e9607a2353d8342fd0d\n",
            "Successfully built unsloth\n",
            "Installing collected packages: unsloth\n",
            "Successfully installed unsloth-2024.10.6\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.5)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.5)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "\n",
        "# Install Wandb for monitoring\n",
        "!pip install wandb\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MGegy-T6d27",
        "outputId": "2fe3a3eb-9e63-4995-a4e7-39db51dcdb78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown --fuzzy https://drive.google.com/file/d/17x7am_JGRXfiwNO68mv3yOCpbLK-7IDA/view?usp=drive_link"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqrXJ2LI9T2x",
        "outputId": "6444cf13-0093-4c2f-a2c3-0a432319a653"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=17x7am_JGRXfiwNO68mv3yOCpbLK-7IDA\n",
            "From (redirected): https://drive.google.com/uc?id=17x7am_JGRXfiwNO68mv3yOCpbLK-7IDA&confirm=t&uuid=0b8cae49-bd31-4fe1-adec-c220c65c2843\n",
            "To: /content/train.csv\n",
            "100% 185M/185M [00:04<00:00, 41.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add HuggingFace's API token\n",
        "\n",
        "1. Get HuggingFace's API at: https://huggingface.co/settings/profile\n",
        "2. Store it at Colab's Secret:\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "hEgIJylo7k5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Huggingface'token with write permission\n",
        "# Go to: https://huggingface.co/settings/tokens\n",
        "# Then create a token with write permission\n",
        "from google.colab import userdata\n",
        "\n",
        "HUGGINGFACE_TOKEN = userdata.get('HF_TOKEN')"
      ],
      "metadata": {
        "id": "6UG9lnSj7Wjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FkhOoGui6ZRT",
        "outputId": "d1fa2ad8-40eb-420d-b6d1-7d927bce0238"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "# Login to Hugging Face\n",
        "from huggingface_hub import login\n",
        "login(token = HUGGINGFACE_TOKEN)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382,
          "referenced_widgets": [
            "937dd00931aa4df098d6a28864b12f84",
            "7023619946bb471b8ae7333368a97b75",
            "f88f447e252941fdb0317ffa8b165ba9",
            "bce31ee1f39846269a44b4b94ca8a1ef",
            "1fb5542ffc964054bb390ce63588b306",
            "8608a86a3a3442c1a6ce2f7c72d437e5",
            "1c9895efc42543569dc18bcf8cc196e1",
            "e362219d5dc24168a353d52b7e51a5ab",
            "eef602b0634143669ca80913ef3f8208",
            "84a6bf3a6e6d405da0d9a25e9ed74614",
            "5f971353e9574b6c90e7939eef28aa0b",
            "319b10939a3e402aaa70fbf155d28f1f",
            "8ef36d430bd54e0f961e00cd03fb811e",
            "c2f619b3a3594017ae3965df0c47db5f",
            "19b859b6efce46a5a866aabe1e4e1e50",
            "f08584b583d8404d9bdb60d6359d5306",
            "651909ad0c7f414d8211691a76aabdb1",
            "e20b3a647fca4a9ea74f23417610351f",
            "063aaad12923422d8ac0d8d63b048fb1",
            "7ad3bc4b7c1a4765889e8615c2eb6d65",
            "ba442e303b694eab874f50ffc836f463",
            "c1d1746b1f1642feab578620396c3bdc",
            "b784f722e47c4b6398331d92770c3aed",
            "5d92d0065a604b9aa68ed9f682b958f4",
            "4fbdbacda683400c92fb4d93f9276d43",
            "a3be1d8618074283b1328b5076444394",
            "0da9385fa00a48d8ba5d649a8c9a3a25",
            "8ed0f83f19614a339a1fe79eaadf4a44",
            "c624711588ce42fba41607f3be0e0495",
            "da066b1eab0e44e2abaf082927c1c3dc",
            "14448d866b874621a8ed68d0a2377c99",
            "914dc628d4564c1ea37a0c000ed84ba9",
            "a93a628d1fff42c5adef38330b8418eb",
            "4a9b6c57c3a146f692f3a55364c95a09",
            "447e42c16f4e4634bdbb43bafa0bca3d",
            "c04b93587f9a4c4490c14010fce56883",
            "2bc3f4ce4ede45cd8be371394d7483ee",
            "cb38fb51681b41f1bfccd3a4c4e36d05",
            "c19f1c467ba143eaaed55720216e96be",
            "76ec3274a93245aba38d65b028bf2e60",
            "ae43194322cb4c3794d632cc7a784d0c",
            "01fe3097b9b2434bb44f6413f4d2c69e",
            "b906b1cff84e48f69d38dd7b2a2fe7cc",
            "569a84817ebf4cf2b85674b957fdd567",
            "0abc69a9ab6f4945b3564a54fcc6c9e6",
            "fef35acf7d734c04a64f464e773eddbc",
            "a58bab4216fc4d85b1b3b94d64ed9ea4",
            "bb2854f312ee449c910b741da3b70435",
            "48dab2c7e5d14786acf7297d48808c60",
            "09eae10617fb44caac4e8f427666348b",
            "78f5f5688f0b40d29f12737017b4241e",
            "843cc386c9194e5c8e9b4483c3b7ee5d",
            "1b09d384843e4f62b75174dc2d60a5a0",
            "bad71bd7c7514f1dbe9cd9d4e936fb3b",
            "73c1ff35ff9942e4ab21211e37472821"
          ]
        },
        "id": "QmUBVEnvCDJv",
        "outputId": "43bc5cc6-b932-45e9-849f-6363757a427a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "==((====))==  Unsloth 2024.10.6: Fast Llama patching. Transformers = 4.44.2.\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.5.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post2. FA2 = False]\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "937dd00931aa4df098d6a28864b12f84"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "319b10939a3e402aaa70fbf155d28f1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.6k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b784f722e47c4b6398331d92770c3aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a9b6c57c3a146f692f3a55364c95a09"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0abc69a9ab6f4945b3564a54fcc6c9e6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: We fixed a gradient accumulation bug, but it seems like you don't have the latest transformers version!\n",
            "Please update transformers, TRL and unsloth via:\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-1B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "3a10c331-f7b2-44f7-c7c0-db700ed4947c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2024.10.6 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data preparation"
      ],
      "metadata": {
        "id": "Jahsr4_O_Fk9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def preprocess_row_data(row: pd.Series) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Preprocess row data from BKAI\n",
        "    \"\"\"\n",
        "    result: list[dict] = []\n",
        "    question = row[\"question\"].replace('\"', \"\").replace(\"'\", \"\").strip(\"\\n\").strip()\n",
        "    qid = row[\"qid\"]\n",
        "\n",
        "    cid = [int(x) for x in row[\"cid\"].strip(\"[] \").split(\" \") if x]\n",
        "    context = row[\"context\"].strip(\"[]\").split(\"'\\n\")\n",
        "\n",
        "    assert len(cid) == len(context), f\"{len(cid)} != {len(context)} for {row}\"\n",
        "    for i in range(len(cid)):\n",
        "        result.append(\n",
        "            {\n",
        "                \"question\": question,\n",
        "                \"context\": context[i]\n",
        "                .replace('\"', \"\")\n",
        "                .replace(\"'\", \"\")\n",
        "                .strip(\"\\n\")\n",
        "                .strip(),\n",
        "                \"cid\": cid[i],\n",
        "                \"qid\": qid,\n",
        "            }\n",
        "        )\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "columns = df.columns\n",
        "\n",
        "all_rows = []\n",
        "\n",
        "for index, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "    all_rows.extend(preprocess_row_data(row))\n",
        "\n",
        "processed_df = pd.DataFrame(all_rows)\n",
        "\n",
        "processed_df.to_csv(\"preprocessed_train.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MviV3hb9rAk",
        "outputId": "e2036e1d-1ee6-4eba-e60b-21517e8b4088"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 119456/119456 [00:08<00:00, 14076.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_row_data(row: pd.Series) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Preprocess row data from BKAI to FineTome 100k format\n",
        "    \"\"\"\n",
        "    result: list[tuple[dict, dict]] = []\n",
        "    question = row[\"question\"]\n",
        "\n",
        "    context = row[\"context\"]\n",
        "\n",
        "    result.append(\n",
        "        [\n",
        "            {\n",
        "                \"from\": \"human\",\n",
        "                \"value\": question,\n",
        "            },\n",
        "            {\n",
        "                \"from\": \"gpt\",\n",
        "                \"value\": context,\n",
        "            }\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    return result\n",
        "\n",
        "def convert_data_to_FineTome_100k_format(\n",
        "    train_file: str | Path, progess: bool = True\n",
        ") -> list[dict]:\n",
        "    \"\"\"\n",
        "    Convert BKAI data to FineTome 100k format\n",
        "    \"\"\"\n",
        "    assert Path(train_file).suffix == \".csv\", \"Only csv files are supported\"\n",
        "\n",
        "    conversations_list: list[dict] = []\n",
        "    df = pd.read_csv(train_file)\n",
        "\n",
        "    iterrows = tqdm(df.iterrows(), total=len(df)) if progess else df.iterrows()\n",
        "    for _, row in iterrows:\n",
        "        conversations_list.extend(preprocess_row_data(row))\n",
        "\n",
        "    return conversations_list\n",
        "\n"
      ],
      "metadata": {
        "id": "LgLyJbB581Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oPXzJZzHEgXe"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from unsloth.chat_templates import standardize_sharegpt, get_chat_template\n",
        "\n",
        "def load_dataset(\n",
        "    train_file: str | Path, tokenizer: any, progress: bool = False\n",
        ") -> datasets.Dataset:\n",
        "    \"\"\"\n",
        "    Load dataset from csv file\n",
        "    \"\"\"\n",
        "    assert Path(train_file).suffix == \".csv\", \"Only csv files are supported\"\n",
        "    conversations_list = convert_data_to_FineTome_100k_format(\n",
        "        train_file, progess=progress\n",
        "    )\n",
        "\n",
        "    dataset = datasets.Dataset.from_dict({\"conversations\": conversations_list})\n",
        "\n",
        "    tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
        "\n",
        "    def formatting_prompts_func(examples):\n",
        "        convos = examples[\"conversations\"]\n",
        "        texts = [\n",
        "            tokenizer.apply_chat_template(\n",
        "                convo, tokenize=False, add_generation_prompt=False\n",
        "            )\n",
        "            for convo in convos\n",
        "        ]\n",
        "        return {\n",
        "            \"text\": texts,\n",
        "        }\n",
        "\n",
        "    dataset = standardize_sharegpt(dataset)\n",
        "    dataset = dataset.map(\n",
        "        formatting_prompts_func,\n",
        "        batched=True,\n",
        "    )\n",
        "\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"./preprocessed_train.csv\", tokenizer, progress=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "b61b37548a9e49259e3d6975b612dbeb",
            "8dcec1d93b464b2590a0726f4188e777",
            "5b914368517144509bb01b78902f9a6e",
            "86f6d32a99e84ac0a9dfdebc1d24f5bf",
            "9476a8390f4b48eeb7d804d00d03a121",
            "f84feda9a2354b27b6e27a504f51c27a",
            "2563353255794ad993636d68ad9673a8",
            "c866144bc0334031845d74fbfcf84b8a",
            "200f30dae3fa4526bc2d0def440d4271",
            "3b01b50977414df6b400c56d4b2de535",
            "b37f71dd14e04ca4a5076e5c22ed9a08",
            "3e32458835244361a8c637d4cfbe9eb1",
            "9cbe343e338b4aa489c1a75e6054fa57",
            "3f53e8b5a2f94f7a910d6d1ddc1ca91f",
            "d7665fdd294c4138bbbd765392e8f8ca",
            "a73456dcd15f4f6aa69816afa6f411ba",
            "bc98af7613f44d5d992e40a10a94daee",
            "d1d0be18995148fba4d7e9b6e75fa7e1",
            "78d7a88ab6d043b6954d6b2b8cce4faf",
            "1eff9957fec040619c06940eb7dfedc1",
            "ff277dfd6dd64d25920405d77f89b5bb",
            "1225d4db12cf4ac0a4abe65636d7373a"
          ]
        },
        "id": "L2vtM8MN-rdB",
        "outputId": "eeaad94b-c932-49d9-d188-8b1f18468026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 133568/133568 [00:07<00:00, 16837.28it/s]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Standardizing format:   0%|          | 0/133568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b61b37548a9e49259e3d6975b612dbeb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/133568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e32458835244361a8c637d4cfbe9eb1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGFzmplrEy9I",
        "outputId": "a7bf6c94-2faa-425c-ba86-f1aaa63a1331"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'content': 'Chi phí hoạt động dịch vụ của Ngân hàng Hợp tác xã Việt Nam bao gồm những khoản chi nào?',\n",
              "  'role': 'user'},\n",
              " {'content': 'Chi phí\\\\nChi phí của Ngân hàng bao gồm các khoản chi quy định tại Điều 17 Nghị định số 93/2017/NĐ-CP. Cụ thể:\\\\n1. Chi phí lãi và các chi phí tương tự:\\\\na) Chi trả lãi tiền gửi: Chi trả lãi tiền gửi của các quỹ tín dụng nhân dân thành viên; Chi trả lãi tiền gửi của các khách hàng không phải là quỹ tín dụng nhân dân thành viên.\\\\nb) Chi trả lãi tiền vay.\\\\nc) Chi trả lãi phát hành giấy tờ có giá.\\\\nd) Chi khác cho hoạt động tín dụng.\\\\n2. Chi phí hoạt động dịch vụ:\\\\na) Chi về dịch vụ thanh toán.\\\\nb) Chi về dịch vụ ngân quỹ.\\\\nc) Chi về dịch vụ viễn thông.\\\\nd) Chi về nghiệp vụ ủy thác và đại lý.\\\\nđ) Chi về dịch vụ tư vấn.\\\\ne) Chi hoa hồng cho đại lý, môi giới, ủy thác đối với các hoạt động đại lý, môi giới, ủy thác được pháp luật cho phép. Trong đó đối với chi hoa hồng môi giới thực hiện theo quy định sau:\\\\n- Ngân hàng được chi hoa hồng môi giới đối với hoạt động môi giới được pháp luật cho phép.\\\\n...',\n",
              "  'role': 'assistant'}]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "dataset[5][\"conversations\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "ef720ed0-9811-40e6-980e-349b2cb8b297"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nChi phí hoạt động dịch vụ của Ngân hàng Hợp tác xã Việt Nam bao gồm những khoản chi nào?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nChi phí\\\\nChi phí của Ngân hàng bao gồm các khoản chi quy định tại Điều 17 Nghị định số 93/2017/NĐ-CP. Cụ thể:\\\\n1. Chi phí lãi và các chi phí tương tự:\\\\na) Chi trả lãi tiền gửi: Chi trả lãi tiền gửi của các quỹ tín dụng nhân dân thành viên; Chi trả lãi tiền gửi của các khách hàng không phải là quỹ tín dụng nhân dân thành viên.\\\\nb) Chi trả lãi tiền vay.\\\\nc) Chi trả lãi phát hành giấy tờ có giá.\\\\nd) Chi khác cho hoạt động tín dụng.\\\\n2. Chi phí hoạt động dịch vụ:\\\\na) Chi về dịch vụ thanh toán.\\\\nb) Chi về dịch vụ ngân quỹ.\\\\nc) Chi về dịch vụ viễn thông.\\\\nd) Chi về nghiệp vụ ủy thác và đại lý.\\\\nđ) Chi về dịch vụ tư vấn.\\\\ne) Chi hoa hồng cho đại lý, môi giới, ủy thác đối với các hoạt động đại lý, môi giới, ủy thác được pháp luật cho phép. Trong đó đối với chi hoa hồng môi giới thực hiện theo quy định sau:\\\\n- Ngân hàng được chi hoa hồng môi giới đối với hoạt động môi giới được pháp luật cho phép.\\\\n...<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "dataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "## 3. Train the model\n",
        "\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_dir = \"models\""
      ],
      "metadata": {
        "id": "QFH0YclqAcYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "6371dfc432d740d3a3b3a0a8f11fad42",
            "820669d22cb54086ba1f4f2023e06b15",
            "c4dc807cd63c4372aa331de093edaf3c",
            "c06bfbe98a654cbf8c55aabbd5ab0c86",
            "32f391cccfd142d09056a4c3744a6701",
            "400787c155bf43d58977245951caba5b",
            "97af2b145a394bf9bbfaf58db029b628",
            "fdbe2f261d624dfcbf06f7d8af35a111",
            "96943c6545db4e4a9c0d9e5a48f039af",
            "65af07d780e942c885440a4134f438a1",
            "0dde8397bccf4ed6a188595a85733e90"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "58a06636-d0ee-4973-c25c-b862fa571d6e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/133568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6371dfc432d740d3a3b3a0a8f11fad42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 4,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = output_dir,\n",
        "        report_to=\"none\"\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "559bb41cc234454987c712f676075132",
            "6e6b964294b64ef19a8ba5ad15627183",
            "52be173b19384185954b875746bd9f5e",
            "d4cef4ad90394e9cb77712d9d8db74cc",
            "c18d554dba9748969f58a7569c6d5515",
            "9c3118b0550544eb9580448b08bbb725",
            "ac2b4a9adaa449cbafbcc28480e186c1",
            "ab6644add5474dd3a626d07e4f986bb9",
            "015adf9d1866418cabb19c94aeb84a21",
            "9b16cc15cfdb4a289c71d0f8afc061d6",
            "b2c4fa41c45b4eae8a7e2cf6a68f0f02"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "9b017df9-b9ee-4934-aa14-3556b5fb41c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/133568 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "559bb41cc234454987c712f676075132"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "LtsMVtlkUhja",
        "outputId": "0bd789b4-ed18-48c2-c653-8061b700e1de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nChi phí hoạt động dịch vụ của Ngân hàng Hợp tác xã Việt Nam bao gồm những khoản chi nào?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nChi phí\\\\nChi phí của Ngân hàng bao gồm các khoản chi quy định tại Điều 17 Nghị định số 93/2017/NĐ-CP. Cụ thể:\\\\n1. Chi phí lãi và các chi phí tương tự:\\\\na) Chi trả lãi tiền gửi: Chi trả lãi tiền gửi của các quỹ tín dụng nhân dân thành viên; Chi trả lãi tiền gửi của các khách hàng không phải là quỹ tín dụng nhân dân thành viên.\\\\nb) Chi trả lãi tiền vay.\\\\nc) Chi trả lãi phát hành giấy tờ có giá.\\\\nd) Chi khác cho hoạt động tín dụng.\\\\n2. Chi phí hoạt động dịch vụ:\\\\na) Chi về dịch vụ thanh toán.\\\\nb) Chi về dịch vụ ngân quỹ.\\\\nc) Chi về dịch vụ viễn thông.\\\\nd) Chi về nghiệp vụ ủy thác và đại lý.\\\\nđ) Chi về dịch vụ tư vấn.\\\\ne) Chi hoa hồng cho đại lý, môi giới, ủy thác đối với các hoạt động đại lý, môi giới, ủy thác được pháp luật cho phép. Trong đó đối với chi hoa hồng môi giới thực hiện theo quy định sau:\\\\n- Ngân hàng được chi hoa hồng môi giới đối với hoạt động môi giới được pháp luật cho phép.\\\\n...<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "a639e70a-6fa4-4bae-fa84-095e58e91aaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                                                         \\n\\nChi phí\\\\nChi phí của Ngân hàng bao gồm các khoản chi quy định tại Điều 17 Nghị định số 93/2017/NĐ-CP. Cụ thể:\\\\n1. Chi phí lãi và các chi phí tương tự:\\\\na) Chi trả lãi tiền gửi: Chi trả lãi tiền gửi của các quỹ tín dụng nhân dân thành viên; Chi trả lãi tiền gửi của các khách hàng không phải là quỹ tín dụng nhân dân thành viên.\\\\nb) Chi trả lãi tiền vay.\\\\nc) Chi trả lãi phát hành giấy tờ có giá.\\\\nd) Chi khác cho hoạt động tín dụng.\\\\n2. Chi phí hoạt động dịch vụ:\\\\na) Chi về dịch vụ thanh toán.\\\\nb) Chi về dịch vụ ngân quỹ.\\\\nc) Chi về dịch vụ viễn thông.\\\\nd) Chi về nghiệp vụ ủy thác và đại lý.\\\\nđ) Chi về dịch vụ tư vấn.\\\\ne) Chi hoa hồng cho đại lý, môi giới, ủy thác đối với các hoạt động đại lý, môi giới, ủy thác được pháp luật cho phép. Trong đó đối với chi hoa hồng môi giới thực hiện theo quy định sau:\\\\n- Ngân hàng được chi hoa hồng môi giới đối với hoạt động môi giới được pháp luật cho phép.\\\\n...<|eot_id|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "1b14e46e-4c53-4776-bda6-9da153a3ef14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "1.191 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "2eb82273-95ca-4d78-9197-bdbfb9f50622"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 133,568 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 16 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 22,544,384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**** Unsloth: Please use our fixed gradient_accumulation_steps by updating transformers, TRL and Unsloth!\n",
            "`pip install --upgrade --no-cache-dir unsloth git+https://github.com/huggingface/transformers.git git+https://github.com/huggingface/trl.git`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 03:58, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.064500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.013100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.018400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.991700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.861200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.066700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.875700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>2.047600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>1.804500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.981900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>1.795200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>1.748600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>1.844200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>1.982600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.700100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>1.768900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.770400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.761700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>1.742400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.742000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>1.664700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>1.695000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>1.871700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.805400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.757100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>1.702000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>1.666700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>1.843800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>1.763100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.706300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>1.804000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>1.711800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>1.653300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>1.984500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>1.558200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>1.829100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>1.790700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>1.701800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>1.748100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.672800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>1.754500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>1.756200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>1.648500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>1.614300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>1.643100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>1.739900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>1.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>1.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>1.517300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.686700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>1.984400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>1.912500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.692200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>1.833800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.722800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.579200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>1.729600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>1.510000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>1.630900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.546100</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "33afa58c-7e81-40f3-adc8-c316ae3df4cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "251.0644 seconds used for training.\n",
            "4.18 minutes used for training.\n",
            "Peak reserved memory = 6.721 GB.\n",
            "Peak reserved memory for training = 5.53 GB.\n",
            "Peak reserved memory % of max memory = 45.572 %.\n",
            "Peak reserved memory for training % of max memory = 37.497 %.\n"
          ]
        }
      ],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "## 4. Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "5ee64cbf-9aba-4463-f053-dcdea7b76c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nNgười học ngành quản lý khai thác công trình thủy lợi trình độ cao đẳng phải có khả năng học tập và nâng cao trình độ như thế nào?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nNăng lực cần đạt được trong việc học tập\\\\n- Luyện tập hiệu quả theo kế hoạch giáo dục tại các khu vực học tập.\\\\n- Sử dụng tốt các công cụ học tập: máy tính, thiết bị điện tử, tài liệu cơ bản, sách giáo dục; tích cực tham gia hoạt động dạy học ở khu vực học tập của mình.\\\\n- Có đủ năng lực và kinh nghiệm về giáo dục:\\\\n1. Lập chương trình giảng dạy và điều chỉnh theo từng học kỳ.\\\\n2. Đơn giản hóa chương trình giáo dục.\\\\n3. Có phương pháp giảng dạy, học tập và chuẩn bị cho học tập của mình và các học sinh.\\\\n4. Hiệu chỉnh, sửa đổi sách giáo khoa cho các lớp học thuộc chương trình, chủ đề giáo dục và sách giáo khoa theo nhu cầu của trường.<|eot_id|>']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Người học ngành quản lý khai thác công trình thủy lợi trình độ cao đẳng phải có khả năng học tập và nâng cao trình độ như thế nào?\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 256, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "## 5. Save the model\n",
        "\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, create_repo, upload_folder\n",
        "\n",
        "login(token=HUGGINGFACE_TOKEN)\n",
        "\n",
        "# Add your model name here hf_username/model_name\n",
        "hf_model_name = \"StoicCodingLab/test_model\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLh3lOcvB7IX",
        "outputId": "126a83ec-c746-4fa6-d0e2-476e4fabd930"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a674228-32fa-4d34-803e-767e26b2efa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: You have 1 CPUs. Using `safe_serialization` is 10x slower.\n",
            "We shall switch to Pytorch saving, which will take 3 minutes and not 30 minutes.\n",
            "To force `safe_serialization`, set it to `None` instead.\n",
            "Unsloth: Kaggle/Colab has limited disk space. We need to delete the downloaded\n",
            "model which will save 4-16GB of disk space, allowing you to save on Kaggle/Colab.\n",
            "Unsloth: Will remove a cached repo with size 1.0G\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Merging 4bit and LoRA weights to 16bit...\n",
            "Unsloth: Will use up to 4.17 out of 12.67 RAM for saving.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:01<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Saving tokenizer... Done.\n",
            "Unsloth: Saving model... This might take 5 minutes for Llama-7b...\n",
            "Unsloth: Saving models/pytorch_model.bin...\n",
            "Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Converting llama model. Can use fast conversion = False.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Conversion from QLoRA to GGUF information\n",
            "   \\\\   /|    [0] Installing llama.cpp will take 3 minutes.\n",
            "O^O/ \\_/ \\    [1] Converting HF to GGUF 16bits will take 3 minutes.\n",
            "\\        /    [2] Converting GGUF 16bits to ['q4_k_m', 'q8_0', 'q5_k_m'] will take 10 minutes each.\n",
            " \"-____-\"     In total, you will have to wait at least 16 minutes.\n",
            "\n",
            "Unsloth: [0] Installing llama.cpp. This will take 3 minutes...\n",
            "Unsloth: [1] Converting model at models into f16 GGUF format.\n",
            "The output location will be /content/models/unsloth.F16.gguf\n",
            "This will take 3 minutes...\n",
            "INFO:hf-to-gguf:Loading model: models\n",
            "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
            "INFO:hf-to-gguf:Exporting model...\n",
            "INFO:hf-to-gguf:rope_freqs.weight,           torch.float32 --> F32, shape = {32}\n",
            "INFO:hf-to-gguf:gguf: loading model part 'pytorch_model.bin'\n",
            "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {2048, 128256}\n",
            "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {2048, 512}\n",
            "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {2048, 2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {2048, 8192}\n",
            "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {8192, 2048}\n",
            "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {2048}\n",
            "INFO:hf-to-gguf:Set meta model\n",
            "INFO:hf-to-gguf:Set model parameters\n",
            "INFO:hf-to-gguf:gguf: context length = 131072\n",
            "INFO:hf-to-gguf:gguf: embedding length = 2048\n",
            "INFO:hf-to-gguf:gguf: feed forward length = 8192\n",
            "INFO:hf-to-gguf:gguf: head count = 32\n",
            "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
            "INFO:hf-to-gguf:gguf: rope theta = 500000.0\n",
            "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
            "INFO:hf-to-gguf:gguf: file type = 1\n",
            "INFO:hf-to-gguf:Set model tokenizer\n",
            "INFO:gguf.vocab:Adding 280147 merge(s).\n",
            "INFO:gguf.vocab:Setting special token type bos to 128000\n",
            "INFO:gguf.vocab:Setting special token type eos to 128009\n",
            "INFO:gguf.vocab:Setting special token type pad to 128004\n",
            "INFO:gguf.vocab:Setting chat_template to {{- bos_token }}\n",
            "{%- if custom_tools is defined %}\n",
            "    {%- set tools = custom_tools %}\n",
            "{%- endif %}\n",
            "{%- if not tools_in_user_message is defined %}\n",
            "    {%- set tools_in_user_message = true %}\n",
            "{%- endif %}\n",
            "{%- if not date_string is defined %}\n",
            "    {%- set date_string = \"26 July 2024\" %}\n",
            "{%- endif %}\n",
            "{%- if not tools is defined %}\n",
            "    {%- set tools = none %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- This block extracts the system message, so we can slot it into the right place. #}\n",
            "{%- if messages[0]['role'] == 'system' %}\n",
            "    {%- set system_message = messages[0]['content'] %}\n",
            "    {%- set messages = messages[1:] %}\n",
            "{%- else %}\n",
            "    {%- set system_message = \"\" %}\n",
            "{%- endif %}\n",
            "\n",
            "{#- System message + builtin tools #}\n",
            "{{- \"<|start_header_id|>system<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "{%- if builtin_tools is defined or tools is not none %}\n",
            "    {{- \"Environment: ipython\n",
            "\" }}\n",
            "{%- endif %}\n",
            "{%- if builtin_tools is defined %}\n",
            "    {{- \"Tools: \" + builtin_tools | reject('equalto', 'code_interpreter') | join(\", \") + \"\n",
            "\n",
            "\"}}\n",
            "{%- endif %}\n",
            "{{- \"Cutting Knowledge Date: December 2023\n",
            "\" }}\n",
            "{{- \"Today Date: \" + date_string + \"\n",
            "\n",
            "\" }}\n",
            "{%- if tools is not none and not tools_in_user_message %}\n",
            "    {{- \"You have access to the following functions. To call a function, please respond with JSON for a function call.\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "{%- endif %}\n",
            "{{- system_message }}\n",
            "{{- \"<|eot_id|>\" }}\n",
            "\n",
            "{#- Custom tools are passed in a user message with some extra guidance #}\n",
            "{%- if tools_in_user_message and not tools is none %}\n",
            "    {#- Extract the first user message so we can plug it in here #}\n",
            "    {%- if messages | length != 0 %}\n",
            "        {%- set first_user_message = messages[0]['content'] %}\n",
            "        {%- set messages = messages[1:] %}\n",
            "    {%- else %}\n",
            "        {{- raise_exception(\"Cannot put tools in the first user message when there's no first user message!\") }}\n",
            "{%- endif %}\n",
            "    {{- '<|start_header_id|>user<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "    {{- \"Given the following functions, please respond with a JSON for a function call \" }}\n",
            "    {{- \"with its proper arguments that best answers the given prompt.\n",
            "\n",
            "\" }}\n",
            "    {{- 'Respond in the format {\"name\": function name, \"parameters\": dictionary of argument name and its value}.' }}\n",
            "    {{- \"Do not use variables.\n",
            "\n",
            "\" }}\n",
            "    {%- for t in tools %}\n",
            "        {{- t | tojson(indent=4) }}\n",
            "        {{- \"\n",
            "\n",
            "\" }}\n",
            "    {%- endfor %}\n",
            "    {{- first_user_message + \"<|eot_id|>\"}}\n",
            "{%- endif %}\n",
            "\n",
            "{%- for message in messages %}\n",
            "    {%- if not (message.role == 'ipython' or message.role == 'tool' or 'tool_calls' in message) %}\n",
            "        {{- '<|start_header_id|>' + message['role'] + '<|end_header_id|>\n",
            "\n",
            "'+ message['content'] + '<|eot_id|>' }}\n",
            "    {%- elif 'tool_calls' in message %}\n",
            "        {%- if not message.tool_calls|length == 1 %}\n",
            "            {{- raise_exception(\"This model only supports single tool-calls at once!\") }}\n",
            "        {%- endif %}\n",
            "        {%- set tool_call = message.tool_calls[0].function %}\n",
            "        {%- if builtin_tools is defined and tool_call.name in builtin_tools %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- \"<|python_tag|>\" + tool_call.name + \".call(\" }}\n",
            "            {%- for arg_name, arg_val in tool_call.arguments | items %}\n",
            "                {{- arg_name + '=\"' + arg_val + '\"' }}\n",
            "                {%- if not loop.last %}\n",
            "                    {{- \", \" }}\n",
            "                {%- endif %}\n",
            "                {%- endfor %}\n",
            "            {{- \")\" }}\n",
            "        {%- else  %}\n",
            "            {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' -}}\n",
            "            {{- '{\"name\": \"' + tool_call.name + '\", ' }}\n",
            "            {{- '\"parameters\": ' }}\n",
            "            {{- tool_call.arguments | tojson }}\n",
            "            {{- \"}\" }}\n",
            "        {%- endif %}\n",
            "        {%- if builtin_tools is defined %}\n",
            "            {#- This means we're in ipython mode #}\n",
            "            {{- \"<|eom_id|>\" }}\n",
            "        {%- else %}\n",
            "            {{- \"<|eot_id|>\" }}\n",
            "        {%- endif %}\n",
            "    {%- elif message.role == \"tool\" or message.role == \"ipython\" %}\n",
            "        {{- \"<|start_header_id|>ipython<|end_header_id|>\n",
            "\n",
            "\" }}\n",
            "        {%- if message.content is mapping or message.content is iterable %}\n",
            "            {{- message.content | tojson }}\n",
            "        {%- else %}\n",
            "            {{- message.content }}\n",
            "        {%- endif %}\n",
            "        {{- \"<|eot_id|>\" }}\n",
            "    {%- endif %}\n",
            "{%- endfor %}\n",
            "{%- if add_generation_prompt %}\n",
            "    {{- '<|start_header_id|>assistant<|end_header_id|>\n",
            "\n",
            "' }}\n",
            "{%- endif %}\n",
            "\n",
            "INFO:hf-to-gguf:Set model quantization version\n",
            "INFO:gguf.gguf_writer:Writing the following files:\n",
            "INFO:gguf.gguf_writer:/content/models/unsloth.F16.gguf: n_tensors = 147, total_size = 2.5G\n",
            "Writing: 100%|██████████| 2.47G/2.47G [00:46<00:00, 52.8Mbyte/s]\n",
            "INFO:hf-to-gguf:Model successfully exported to /content/models/unsloth.F16.gguf\n",
            "Unsloth: Conversion completed! Output location: /content/models/unsloth.F16.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q4_k_m. This will take 20 minutes...\n",
            "main: build = 3972 (167a5156)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/models/unsloth.F16.gguf' to '/content/models/unsloth.Q4_K_M.gguf' as Q4_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 147 tensors from /content/models/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 1B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
            "[   3/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[   5/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[   7/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   8/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  10/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  14/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  16/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  17/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  19/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  23/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  25/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  26/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  28/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  32/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  34/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  35/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  37/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  41/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  43/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  44/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  46/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  50/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  52/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  53/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  55/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  59/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  61/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  62/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  64/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  68/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  70/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  71/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  73/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  77/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  79/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  80/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  82/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  86/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  88/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  89/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  91/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[  95/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[  97/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  98/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 100/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 104/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 106/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 107/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 109/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 113/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 115/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 116/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 118/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 122/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 124/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 125/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 127/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 131/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 133/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 134/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 136/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q4_K .. size =     2.00 MiB ->     0.56 MiB\n",
            "[ 140/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q4_K .. size =     8.00 MiB ->     2.25 MiB\n",
            "[ 142/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 143/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q4_K .. size =    32.00 MiB ->     9.00 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 145/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "llama_model_quantize_internal: model size  =  2357.26 MB\n",
            "llama_model_quantize_internal: quant size  =   762.81 MB\n",
            "\n",
            "main: quantize time = 137241.94 ms\n",
            "main:    total time = 137241.94 ms\n",
            "Unsloth: Conversion completed! Output location: /content/models/unsloth.Q4_K_M.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q8_0. This will take 20 minutes...\n",
            "main: build = 3972 (167a5156)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/models/unsloth.F16.gguf' to '/content/models/unsloth.Q8_0.gguf' as Q8_0 using 4 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 147 tensors from /content/models/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 1B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q8_0 .. size =   501.00 MiB ->   266.16 MiB\n",
            "[   3/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[   5/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[   7/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   8/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  10/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  14/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  16/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  17/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  19/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  23/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  25/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  26/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  28/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  32/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  34/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  35/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  37/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  41/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  43/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  44/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  46/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  50/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  52/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  53/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  55/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  59/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  61/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  62/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  64/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  68/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  70/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  71/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  73/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  77/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  79/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  80/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  82/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  86/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  88/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  89/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  91/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  95/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[  97/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  98/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 100/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 104/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 106/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 107/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 109/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 113/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 115/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 116/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 118/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 122/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 124/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 125/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 127/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 131/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 133/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 134/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 136/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 140/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q8_0 .. size =     2.00 MiB ->     1.06 MiB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q8_0 .. size =     8.00 MiB ->     4.25 MiB\n",
            "[ 142/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 143/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q8_0 .. size =    32.00 MiB ->    17.00 MiB\n",
            "[ 145/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "llama_model_quantize_internal: model size  =  2357.26 MB\n",
            "llama_model_quantize_internal: quant size  =  1252.41 MB\n",
            "\n",
            "main: quantize time = 31786.21 ms\n",
            "main:    total time = 31786.21 ms\n",
            "Unsloth: Conversion completed! Output location: /content/models/unsloth.Q8_0.gguf\n",
            "Unsloth: [2] Converting GGUF 16bit into q5_k_m. This will take 20 minutes...\n",
            "main: build = 3972 (167a5156)\n",
            "main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n",
            "main: quantizing '/content/models/unsloth.F16.gguf' to '/content/models/unsloth.Q5_K_M.gguf' as Q5_K_M using 4 threads\n",
            "llama_model_loader: loaded meta data with 30 key-value pairs and 147 tensors from /content/models/unsloth.F16.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama 3.2 1b Instruct Bnb 4bit\n",
            "llama_model_loader: - kv   3:                       general.organization str              = Unsloth\n",
            "llama_model_loader: - kv   4:                           general.finetune str              = instruct-bnb-4bit\n",
            "llama_model_loader: - kv   5:                           general.basename str              = llama-3.2\n",
            "llama_model_loader: - kv   6:                         general.size_label str              = 1B\n",
            "llama_model_loader: - kv   7:                          llama.block_count u32              = 16\n",
            "llama_model_loader: - kv   8:                       llama.context_length u32              = 131072\n",
            "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 2048\n",
            "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 8192\n",
            "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
            "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 64\n",
            "llama_model_loader: - kv  20:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  21:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  22:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  23:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  24:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  26:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  27:            tokenizer.ggml.padding_token_id u32              = 128004\n",
            "llama_model_loader: - kv  28:                    tokenizer.chat_template str              = {{- bos_token }}\\n{%- if custom_tools ...\n",
            "llama_model_loader: - kv  29:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - type  f32:   34 tensors\n",
            "llama_model_loader: - type  f16:  113 tensors\n",
            "[   1/ 147]                    rope_freqs.weight - [   32,     1,     1,     1], type =    f32, size =    0.000 MB\n",
            "[   2/ 147]                    token_embd.weight - [ 2048, 128256,     1,     1], type =    f16, converting to q6_K .. size =   501.00 MiB ->   205.49 MiB\n",
            "[   3/ 147]                  blk.0.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   4/ 147]                  blk.0.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[   5/ 147]                  blk.0.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[   6/ 147]             blk.0.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[   7/ 147]                blk.0.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   8/ 147]                  blk.0.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[   9/ 147]                blk.0.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  10/ 147]               blk.0.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  11/ 147]                blk.0.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  12/ 147]                  blk.1.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  13/ 147]                  blk.1.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  14/ 147]                  blk.1.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  15/ 147]             blk.1.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  16/ 147]                blk.1.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  17/ 147]                  blk.1.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  18/ 147]                blk.1.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  19/ 147]               blk.1.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  20/ 147]                blk.1.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  21/ 147]                  blk.2.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  22/ 147]                  blk.2.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  23/ 147]                  blk.2.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  24/ 147]             blk.2.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  25/ 147]                blk.2.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  26/ 147]                  blk.2.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  27/ 147]                blk.2.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  28/ 147]               blk.2.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  29/ 147]                blk.2.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  30/ 147]                  blk.3.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  31/ 147]                  blk.3.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  32/ 147]                  blk.3.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  33/ 147]             blk.3.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  34/ 147]                blk.3.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  35/ 147]                  blk.3.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  36/ 147]                blk.3.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  37/ 147]               blk.3.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  38/ 147]                blk.3.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  39/ 147]                  blk.4.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  40/ 147]                  blk.4.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  41/ 147]                  blk.4.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  42/ 147]             blk.4.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  43/ 147]                blk.4.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  44/ 147]                  blk.4.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  45/ 147]                blk.4.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  46/ 147]               blk.4.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  47/ 147]                blk.4.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  48/ 147]                  blk.5.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  49/ 147]                  blk.5.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  50/ 147]                  blk.5.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  51/ 147]             blk.5.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  52/ 147]                blk.5.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  53/ 147]                  blk.5.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  54/ 147]                blk.5.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  55/ 147]               blk.5.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  56/ 147]                blk.5.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  57/ 147]                  blk.6.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  58/ 147]                  blk.6.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  59/ 147]                  blk.6.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  60/ 147]             blk.6.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  61/ 147]                blk.6.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  62/ 147]                  blk.6.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  63/ 147]                blk.6.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  64/ 147]               blk.6.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  65/ 147]                blk.6.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  66/ 147]                  blk.7.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  67/ 147]                  blk.7.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  68/ 147]                  blk.7.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  69/ 147]             blk.7.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  70/ 147]                blk.7.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  71/ 147]                  blk.7.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  72/ 147]                blk.7.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[  73/ 147]               blk.7.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  74/ 147]                blk.7.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  75/ 147]                  blk.8.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  76/ 147]                  blk.8.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  77/ 147]                  blk.8.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  78/ 147]             blk.8.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  79/ 147]                blk.8.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  80/ 147]                  blk.8.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  81/ 147]                blk.8.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  82/ 147]               blk.8.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  83/ 147]                blk.8.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  84/ 147]                  blk.9.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  85/ 147]                  blk.9.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  86/ 147]                  blk.9.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  87/ 147]             blk.9.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  88/ 147]                blk.9.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  89/ 147]                  blk.9.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  90/ 147]                blk.9.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  91/ 147]               blk.9.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  92/ 147]                blk.9.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[  93/ 147]                 blk.10.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  94/ 147]                 blk.10.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[  95/ 147]                 blk.10.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[  96/ 147]            blk.10.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[  97/ 147]               blk.10.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  98/ 147]                 blk.10.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[  99/ 147]               blk.10.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 100/ 147]              blk.10.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 101/ 147]               blk.10.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 102/ 147]                 blk.11.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 103/ 147]                 blk.11.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 104/ 147]                 blk.11.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 105/ 147]            blk.11.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 106/ 147]               blk.11.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 107/ 147]                 blk.11.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 108/ 147]               blk.11.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 109/ 147]              blk.11.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 110/ 147]               blk.11.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 111/ 147]                 blk.12.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 112/ 147]                 blk.12.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 113/ 147]                 blk.12.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 114/ 147]            blk.12.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 115/ 147]               blk.12.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 116/ 147]                 blk.12.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 117/ 147]               blk.12.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 118/ 147]              blk.12.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 119/ 147]               blk.12.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 120/ 147]                 blk.13.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 121/ 147]                 blk.13.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 122/ 147]                 blk.13.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 123/ 147]            blk.13.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 124/ 147]               blk.13.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 125/ 147]                 blk.13.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 126/ 147]               blk.13.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 127/ 147]              blk.13.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 128/ 147]               blk.13.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 129/ 147]                 blk.14.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 130/ 147]                 blk.14.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 131/ 147]                 blk.14.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 132/ 147]            blk.14.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 133/ 147]               blk.14.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 134/ 147]                 blk.14.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 135/ 147]               blk.14.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 136/ 147]              blk.14.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 137/ 147]               blk.14.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 138/ 147]                 blk.15.attn_q.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 139/ 147]                 blk.15.attn_k.weight - [ 2048,   512,     1,     1], type =    f16, converting to q5_K .. size =     2.00 MiB ->     0.69 MiB\n",
            "[ 140/ 147]                 blk.15.attn_v.weight - [ 2048,   512,     1,     1], type =    f16, converting to q6_K .. size =     2.00 MiB ->     0.82 MiB\n",
            "[ 141/ 147]            blk.15.attn_output.weight - [ 2048,  2048,     1,     1], type =    f16, converting to q5_K .. size =     8.00 MiB ->     2.75 MiB\n",
            "[ 142/ 147]               blk.15.ffn_gate.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 143/ 147]                 blk.15.ffn_up.weight - [ 2048,  8192,     1,     1], type =    f16, converting to q5_K .. size =    32.00 MiB ->    11.00 MiB\n",
            "[ 144/ 147]               blk.15.ffn_down.weight - [ 8192,  2048,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
            "[ 145/ 147]              blk.15.attn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 146/ 147]               blk.15.ffn_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "[ 147/ 147]                   output_norm.weight - [ 2048,     1,     1,     1], type =    f32, size =    0.008 MB\n",
            "llama_model_quantize_internal: model size  =  2357.26 MB\n",
            "llama_model_quantize_internal: quant size  =   861.81 MB\n",
            "\n",
            "main: quantize time = 112669.07 ms\n",
            "main:    total time = 112669.07 ms\n",
            "Unsloth: Conversion completed! Output location: /content/models/unsloth.Q5_K_M.gguf\n",
            "Unsloth: Saved Ollama Modelfile to models/Modelfile\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "HfHubHTTPError",
          "evalue": " (Request ID: Root=1-671a5c57-0e68381b4f2b195673295c23;ca5bb7a9-8835-43f0-8930-3688ef49520a)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"hienhayho\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content, make sure you have a token with the `write` role.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 403 Client Error: Forbidden for url: https://huggingface.co/api/repos/create",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-617fca1eb1db>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mcreate_repo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhf_model_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m upload_folder(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mcreate_repo\u001b[0;34m(self, repo_id, token, private, repo_type, exist_ok, resource_group_id, space_sdk, space_hardware, space_storage, space_sleep_time, space_secrets, space_variables)\u001b[0m\n\u001b[1;32m   3361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m             \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexist_ok\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m409\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_errors.py\u001b[0m in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    365\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0;34m\"make sure you have a token with the `write` role.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             )\n\u001b[0;32m--> 367\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHfHubHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHfHubHTTPError\u001b[0m:  (Request ID: Root=1-671a5c57-0e68381b4f2b195673295c23;ca5bb7a9-8835-43f0-8930-3688ef49520a)\n\n403 Forbidden: You don't have the rights to create a model under the namespace \"hienhayho\".\nCannot access content at: https://huggingface.co/api/repos/create.\nIf you are trying to create or update content, make sure you have a token with the `write` role."
          ]
        }
      ],
      "source": [
        "model.save_pretrained_gguf(\n",
        "    output_dir,\n",
        "    tokenizer,\n",
        "    quantization_method=[\n",
        "        \"q4_k_m\",\n",
        "        \"q8_0\",\n",
        "        \"q5_k_m\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "create_repo(hf_model_name, repo_type=\"model\")\n",
        "\n",
        "upload_folder(\n",
        "    folder_path=output_dir,\n",
        "    repo_id=hf_model_name,\n",
        "    repo_type=\"model\",\n",
        "    commit_message=\"Upload model files\",\n",
        "    ignore_patterns=[\".git*\", \"*.ipynb\"],\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "937dd00931aa4df098d6a28864b12f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7023619946bb471b8ae7333368a97b75",
              "IPY_MODEL_f88f447e252941fdb0317ffa8b165ba9",
              "IPY_MODEL_bce31ee1f39846269a44b4b94ca8a1ef"
            ],
            "layout": "IPY_MODEL_1fb5542ffc964054bb390ce63588b306"
          }
        },
        "7023619946bb471b8ae7333368a97b75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8608a86a3a3442c1a6ce2f7c72d437e5",
            "placeholder": "​",
            "style": "IPY_MODEL_1c9895efc42543569dc18bcf8cc196e1",
            "value": "model.safetensors: 100%"
          }
        },
        "f88f447e252941fdb0317ffa8b165ba9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e362219d5dc24168a353d52b7e51a5ab",
            "max": 1027676737,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eef602b0634143669ca80913ef3f8208",
            "value": 1027676737
          }
        },
        "bce31ee1f39846269a44b4b94ca8a1ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84a6bf3a6e6d405da0d9a25e9ed74614",
            "placeholder": "​",
            "style": "IPY_MODEL_5f971353e9574b6c90e7939eef28aa0b",
            "value": " 1.03G/1.03G [00:24&lt;00:00, 42.5MB/s]"
          }
        },
        "1fb5542ffc964054bb390ce63588b306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8608a86a3a3442c1a6ce2f7c72d437e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c9895efc42543569dc18bcf8cc196e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e362219d5dc24168a353d52b7e51a5ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eef602b0634143669ca80913ef3f8208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "84a6bf3a6e6d405da0d9a25e9ed74614": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f971353e9574b6c90e7939eef28aa0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "319b10939a3e402aaa70fbf155d28f1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ef36d430bd54e0f961e00cd03fb811e",
              "IPY_MODEL_c2f619b3a3594017ae3965df0c47db5f",
              "IPY_MODEL_19b859b6efce46a5a866aabe1e4e1e50"
            ],
            "layout": "IPY_MODEL_f08584b583d8404d9bdb60d6359d5306"
          }
        },
        "8ef36d430bd54e0f961e00cd03fb811e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_651909ad0c7f414d8211691a76aabdb1",
            "placeholder": "​",
            "style": "IPY_MODEL_e20b3a647fca4a9ea74f23417610351f",
            "value": "generation_config.json: 100%"
          }
        },
        "c2f619b3a3594017ae3965df0c47db5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_063aaad12923422d8ac0d8d63b048fb1",
            "max": 184,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7ad3bc4b7c1a4765889e8615c2eb6d65",
            "value": 184
          }
        },
        "19b859b6efce46a5a866aabe1e4e1e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba442e303b694eab874f50ffc836f463",
            "placeholder": "​",
            "style": "IPY_MODEL_c1d1746b1f1642feab578620396c3bdc",
            "value": " 184/184 [00:00&lt;00:00, 11.3kB/s]"
          }
        },
        "f08584b583d8404d9bdb60d6359d5306": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "651909ad0c7f414d8211691a76aabdb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e20b3a647fca4a9ea74f23417610351f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "063aaad12923422d8ac0d8d63b048fb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ad3bc4b7c1a4765889e8615c2eb6d65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba442e303b694eab874f50ffc836f463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1d1746b1f1642feab578620396c3bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b784f722e47c4b6398331d92770c3aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d92d0065a604b9aa68ed9f682b958f4",
              "IPY_MODEL_4fbdbacda683400c92fb4d93f9276d43",
              "IPY_MODEL_a3be1d8618074283b1328b5076444394"
            ],
            "layout": "IPY_MODEL_0da9385fa00a48d8ba5d649a8c9a3a25"
          }
        },
        "5d92d0065a604b9aa68ed9f682b958f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ed0f83f19614a339a1fe79eaadf4a44",
            "placeholder": "​",
            "style": "IPY_MODEL_c624711588ce42fba41607f3be0e0495",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4fbdbacda683400c92fb4d93f9276d43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da066b1eab0e44e2abaf082927c1c3dc",
            "max": 54598,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_14448d866b874621a8ed68d0a2377c99",
            "value": 54598
          }
        },
        "a3be1d8618074283b1328b5076444394": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_914dc628d4564c1ea37a0c000ed84ba9",
            "placeholder": "​",
            "style": "IPY_MODEL_a93a628d1fff42c5adef38330b8418eb",
            "value": " 54.6k/54.6k [00:00&lt;00:00, 3.88MB/s]"
          }
        },
        "0da9385fa00a48d8ba5d649a8c9a3a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ed0f83f19614a339a1fe79eaadf4a44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c624711588ce42fba41607f3be0e0495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da066b1eab0e44e2abaf082927c1c3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14448d866b874621a8ed68d0a2377c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "914dc628d4564c1ea37a0c000ed84ba9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a93a628d1fff42c5adef38330b8418eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a9b6c57c3a146f692f3a55364c95a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_447e42c16f4e4634bdbb43bafa0bca3d",
              "IPY_MODEL_c04b93587f9a4c4490c14010fce56883",
              "IPY_MODEL_2bc3f4ce4ede45cd8be371394d7483ee"
            ],
            "layout": "IPY_MODEL_cb38fb51681b41f1bfccd3a4c4e36d05"
          }
        },
        "447e42c16f4e4634bdbb43bafa0bca3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c19f1c467ba143eaaed55720216e96be",
            "placeholder": "​",
            "style": "IPY_MODEL_76ec3274a93245aba38d65b028bf2e60",
            "value": "tokenizer.json: 100%"
          }
        },
        "c04b93587f9a4c4490c14010fce56883": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae43194322cb4c3794d632cc7a784d0c",
            "max": 9085657,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_01fe3097b9b2434bb44f6413f4d2c69e",
            "value": 9085657
          }
        },
        "2bc3f4ce4ede45cd8be371394d7483ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b906b1cff84e48f69d38dd7b2a2fe7cc",
            "placeholder": "​",
            "style": "IPY_MODEL_569a84817ebf4cf2b85674b957fdd567",
            "value": " 9.09M/9.09M [00:00&lt;00:00, 43.3MB/s]"
          }
        },
        "cb38fb51681b41f1bfccd3a4c4e36d05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19f1c467ba143eaaed55720216e96be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76ec3274a93245aba38d65b028bf2e60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae43194322cb4c3794d632cc7a784d0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01fe3097b9b2434bb44f6413f4d2c69e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b906b1cff84e48f69d38dd7b2a2fe7cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569a84817ebf4cf2b85674b957fdd567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0abc69a9ab6f4945b3564a54fcc6c9e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fef35acf7d734c04a64f464e773eddbc",
              "IPY_MODEL_a58bab4216fc4d85b1b3b94d64ed9ea4",
              "IPY_MODEL_bb2854f312ee449c910b741da3b70435"
            ],
            "layout": "IPY_MODEL_48dab2c7e5d14786acf7297d48808c60"
          }
        },
        "fef35acf7d734c04a64f464e773eddbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_09eae10617fb44caac4e8f427666348b",
            "placeholder": "​",
            "style": "IPY_MODEL_78f5f5688f0b40d29f12737017b4241e",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "a58bab4216fc4d85b1b3b94d64ed9ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_843cc386c9194e5c8e9b4483c3b7ee5d",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b09d384843e4f62b75174dc2d60a5a0",
            "value": 454
          }
        },
        "bb2854f312ee449c910b741da3b70435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bad71bd7c7514f1dbe9cd9d4e936fb3b",
            "placeholder": "​",
            "style": "IPY_MODEL_73c1ff35ff9942e4ab21211e37472821",
            "value": " 454/454 [00:00&lt;00:00, 31.8kB/s]"
          }
        },
        "48dab2c7e5d14786acf7297d48808c60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09eae10617fb44caac4e8f427666348b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f5f5688f0b40d29f12737017b4241e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "843cc386c9194e5c8e9b4483c3b7ee5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b09d384843e4f62b75174dc2d60a5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bad71bd7c7514f1dbe9cd9d4e936fb3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73c1ff35ff9942e4ab21211e37472821": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b61b37548a9e49259e3d6975b612dbeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8dcec1d93b464b2590a0726f4188e777",
              "IPY_MODEL_5b914368517144509bb01b78902f9a6e",
              "IPY_MODEL_86f6d32a99e84ac0a9dfdebc1d24f5bf"
            ],
            "layout": "IPY_MODEL_9476a8390f4b48eeb7d804d00d03a121"
          }
        },
        "8dcec1d93b464b2590a0726f4188e777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f84feda9a2354b27b6e27a504f51c27a",
            "placeholder": "​",
            "style": "IPY_MODEL_2563353255794ad993636d68ad9673a8",
            "value": "Standardizing format: 100%"
          }
        },
        "5b914368517144509bb01b78902f9a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c866144bc0334031845d74fbfcf84b8a",
            "max": 133568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_200f30dae3fa4526bc2d0def440d4271",
            "value": 133568
          }
        },
        "86f6d32a99e84ac0a9dfdebc1d24f5bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b01b50977414df6b400c56d4b2de535",
            "placeholder": "​",
            "style": "IPY_MODEL_b37f71dd14e04ca4a5076e5c22ed9a08",
            "value": " 133568/133568 [00:04&lt;00:00, 33973.70 examples/s]"
          }
        },
        "9476a8390f4b48eeb7d804d00d03a121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f84feda9a2354b27b6e27a504f51c27a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2563353255794ad993636d68ad9673a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c866144bc0334031845d74fbfcf84b8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200f30dae3fa4526bc2d0def440d4271": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3b01b50977414df6b400c56d4b2de535": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b37f71dd14e04ca4a5076e5c22ed9a08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e32458835244361a8c637d4cfbe9eb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9cbe343e338b4aa489c1a75e6054fa57",
              "IPY_MODEL_3f53e8b5a2f94f7a910d6d1ddc1ca91f",
              "IPY_MODEL_d7665fdd294c4138bbbd765392e8f8ca"
            ],
            "layout": "IPY_MODEL_a73456dcd15f4f6aa69816afa6f411ba"
          }
        },
        "9cbe343e338b4aa489c1a75e6054fa57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc98af7613f44d5d992e40a10a94daee",
            "placeholder": "​",
            "style": "IPY_MODEL_d1d0be18995148fba4d7e9b6e75fa7e1",
            "value": "Map: 100%"
          }
        },
        "3f53e8b5a2f94f7a910d6d1ddc1ca91f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78d7a88ab6d043b6954d6b2b8cce4faf",
            "max": 133568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1eff9957fec040619c06940eb7dfedc1",
            "value": 133568
          }
        },
        "d7665fdd294c4138bbbd765392e8f8ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff277dfd6dd64d25920405d77f89b5bb",
            "placeholder": "​",
            "style": "IPY_MODEL_1225d4db12cf4ac0a4abe65636d7373a",
            "value": " 133568/133568 [00:13&lt;00:00, 10178.11 examples/s]"
          }
        },
        "a73456dcd15f4f6aa69816afa6f411ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc98af7613f44d5d992e40a10a94daee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1d0be18995148fba4d7e9b6e75fa7e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78d7a88ab6d043b6954d6b2b8cce4faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1eff9957fec040619c06940eb7dfedc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ff277dfd6dd64d25920405d77f89b5bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1225d4db12cf4ac0a4abe65636d7373a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6371dfc432d740d3a3b3a0a8f11fad42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_820669d22cb54086ba1f4f2023e06b15",
              "IPY_MODEL_c4dc807cd63c4372aa331de093edaf3c",
              "IPY_MODEL_c06bfbe98a654cbf8c55aabbd5ab0c86"
            ],
            "layout": "IPY_MODEL_32f391cccfd142d09056a4c3744a6701"
          }
        },
        "820669d22cb54086ba1f4f2023e06b15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_400787c155bf43d58977245951caba5b",
            "placeholder": "​",
            "style": "IPY_MODEL_97af2b145a394bf9bbfaf58db029b628",
            "value": "Map (num_proc=2): 100%"
          }
        },
        "c4dc807cd63c4372aa331de093edaf3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fdbe2f261d624dfcbf06f7d8af35a111",
            "max": 133568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_96943c6545db4e4a9c0d9e5a48f039af",
            "value": 133568
          }
        },
        "c06bfbe98a654cbf8c55aabbd5ab0c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65af07d780e942c885440a4134f438a1",
            "placeholder": "​",
            "style": "IPY_MODEL_0dde8397bccf4ed6a188595a85733e90",
            "value": " 133568/133568 [02:25&lt;00:00, 906.20 examples/s]"
          }
        },
        "32f391cccfd142d09056a4c3744a6701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400787c155bf43d58977245951caba5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97af2b145a394bf9bbfaf58db029b628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fdbe2f261d624dfcbf06f7d8af35a111": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96943c6545db4e4a9c0d9e5a48f039af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65af07d780e942c885440a4134f438a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dde8397bccf4ed6a188595a85733e90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "559bb41cc234454987c712f676075132": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e6b964294b64ef19a8ba5ad15627183",
              "IPY_MODEL_52be173b19384185954b875746bd9f5e",
              "IPY_MODEL_d4cef4ad90394e9cb77712d9d8db74cc"
            ],
            "layout": "IPY_MODEL_c18d554dba9748969f58a7569c6d5515"
          }
        },
        "6e6b964294b64ef19a8ba5ad15627183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c3118b0550544eb9580448b08bbb725",
            "placeholder": "​",
            "style": "IPY_MODEL_ac2b4a9adaa449cbafbcc28480e186c1",
            "value": "Map: 100%"
          }
        },
        "52be173b19384185954b875746bd9f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab6644add5474dd3a626d07e4f986bb9",
            "max": 133568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_015adf9d1866418cabb19c94aeb84a21",
            "value": 133568
          }
        },
        "d4cef4ad90394e9cb77712d9d8db74cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b16cc15cfdb4a289c71d0f8afc061d6",
            "placeholder": "​",
            "style": "IPY_MODEL_b2c4fa41c45b4eae8a7e2cf6a68f0f02",
            "value": " 133568/133568 [00:41&lt;00:00, 3046.11 examples/s]"
          }
        },
        "c18d554dba9748969f58a7569c6d5515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c3118b0550544eb9580448b08bbb725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2b4a9adaa449cbafbcc28480e186c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab6644add5474dd3a626d07e4f986bb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015adf9d1866418cabb19c94aeb84a21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b16cc15cfdb4a289c71d0f8afc061d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c4fa41c45b4eae8a7e2cf6a68f0f02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}